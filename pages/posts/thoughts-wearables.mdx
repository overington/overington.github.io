---
title: Thoughts - Wearable and embedded - camera glasses
date: 2022-06-14
description: Some thoughts on wearable and embedded in the form factor of a pair of glasses with a camera
tag: thoughts, wearable
author: Samuel Overington
---

## What is it?

Add a camera to a pair of glasses and in some cases, an HUD to present data to
the wearer, without requiring them to look away from their usual viewpoint.

The more recent implementations (2021/2022) aimed at the general user market
have a fashion first approach, where a tech company has teamed up with
a fashion brand (Meta / Ray-bans), or created the wearable tech in such a way
that it more resembles a piece of fashion, and the tech is portrayed to be just
an added benefit. However, this fashion-forward approach probably hasn't worked
as well as planned - notable, searching for terms like `Snap Spectacles`, or
`Facebook glasses` will usually result in only finding the highly finished
glossy pictures of the advertisement hero image.

![Google Glass Enterprise Edition](/images/blog/2022-06-ideas-wearables.jpg)


## Why?

I have noticed recently that there has been a renewed push for the wearable
product which glues together the camera with the fashion item sunglasses. I say
*fashion* item here, today is now several years after the introduction of
Google glass, which was one of the fore-runners of this type of wearable tech.

[Marques Brownlee](https://www.youtube.com/c/mkbhd) has just made a [great video](https://www.youtube.com/watch?v=xcjZvAFBH_Y) looking at the tech ahead of
its time, and takes a talks about the Google Glass, as well as some other things.

## How does it exist?

Products past and present:

 - [Facebook glasses (Ray-Bans)](https://tcrn.ch/3i8nX7o)
 - [Snap Spectacles / Snap Spectacles AR](https://www.bbc.co.uk/news/technology-57199548)
 - [Microsoft HoloLense 2](https://www.theverge.com/2019/2/24/18235460/microsoft-hololens-2-price-specs-mixed-reality-ar-vr-business-work-features-mwc-2019)
 - [Google Glass](http://www.theverge.com/2012/4/4/2925237/googles-project-glass-augmented-reality-glasses-begin-testing)
 - [Google Glass Enterprise](https://blog.x.company/a-new-chapter-for-glass-c7875d40bf24)

Also I have been thinking about what it would take to run an ML app on an
embedded device such as these. From my time working at Arm in the ML group,
there was lots of great new ML accelerated IP being developed, and the first
microNPU - the [Corstone-300](https://www.arm.com/products/silicon-ip-subsystems/corstone-300) which is aimed at running ML accelerated
applications on embedded / IOT / low power devices.

 - [Corstone-300](https://www.arm.com/products/silicon-ip-subsystems/corstone-300): a package including Ethos U55 MicroNPU, Cortex-M55 Processor, other ip
 - [Ethos U55](https://www.arm.com/products/silicon-ip-cpu/ethos/ethos-u55): A microNPU for accelerating ML applications in a micro-controller
	 form factor, and aimed at coupling with a Cortex-M style processor(eg M55) 
 - [Ethos U65](https://www.arm.com/products/silicon-ip-cpu/ethos/ethos-u65): Similar as above, but aimed at Cortex-A class processors
 - [Cortex M55](https://www.arm.com/products/silicon-ip-cpu/cortex-m/cortex-m55): An embedded processor / microcontroller aimed at running ML
	 workloads, with some added ip to help do the heavy lifting

And in order to run ML applications on embedded devices like these, you need
the ML frameworks - enter TF Lite for microcontrollers:

 - [Gettings started with TinyML / tflite for microcontrollers youtube](https://www.youtube.com/watch?v=gDFWCxrJruQ)
 - arm blog post on [TF lite micro (for micro controllers)](https://community.arm.com/arm-community-blogs/b/ai-and-ml-blog/posts/google-tf-lite-micro-makes-ml-on-arm-even-easier) 
 - [TF Lite for microcontrollers experiments with google](https://experiments.withgoogle.com/collection/tfliteformicrocontrollers)



## What are some current questions or obstructions that it faces?

### Has the problem been the lack of audience take-up or the lack of product meaning?

In a way, the camera glasses hasn't found its purpose yet to both the consumer,
and also perhaps as a product definition itself:

 - Raison d'Ãªtre
 - HUD / feedback / guidance
 - Compute power


### Why would someone **want** to have a camera stuck on their glasses?

It's probably bulkier then a regular set of glasses, so it would probably needs
a good reason to be there.

 - To take pictures
 - Capture the same point of view as the wearer.
 - To not have to carry the camera with your hands - a new type of hands free.
 - The "always on" or "capturing live" nature of the glasses, might enable the
	 wearer to pick up and record things that might not be captured if manually
	 picking up a device to capture images.
 - To interact with the world differently: You might be able to get feedback or
	 information gathered from the lens.
 - Fashion

### What does the HUD give you that a full VR headset could not provide?

 - An overlay, or HUD reduces the latency of the real world part.
 - A VR headset disconnects you from the place and position, and takes you into another world.
 - Where the VR headset takes you is not a real space, it might exist as a digital projection.

### Do the spectacles need a HUD in order to be functional?

This is a hard question to answer; it depends on the use case, weather the user
would be using it for purely capturing purposes.

### What are some ways that the glasses can provide feedback that is not an HUD?

 - Audio (eg telling you directions)
 - Vibration (eg vibrating when something is close)
 - Temporal feedback (eg record now and playback later with augmented, annotated video)
 - Wireless feedback (eg connected devices activate when wireless signal transmits)

### What kind of other sensors could be useful for this type of application

 - **Audio** from a microphone:
	 - Listening conversations around you, understanding the context of what is
			 around you. 
	 - Recognising sounds
	 - Recognising commands
 - Depth.
 - Wireless signal
 - darkness / light
 - motion (axial / accelerometer)



